# -*- coding: utf-8 -*-
"""Mood Based Music Recommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G8knYnIWWnq7D0lKln07Hh4TaEbAGJYB
"""

import pandas as pd
import numpy as np
import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/sample_data/spotify_tracks_dataset.csv')
print("Loaded rows,cols:", df.shape)
print("Columns:", df.columns.tolist()[:40])
df

# Normalize column names to expected ones (safe mapping)
col_map = {}
if 'track_id' in df.columns and 'id' not in df.columns:
    col_map['track_id'] = 'id'
if 'track_name' in df.columns and 'name' not in df.columns:
    col_map['track_name'] = 'name'
if 'artists' in df.columns and 'artist' not in df.columns:
    col_map['artists'] = 'artist'
if 'track_genre' in df.columns and 'genre' not in df.columns:
    col_map['track_genre'] = 'genre'
df.rename(columns=col_map, inplace=True)

# Create track_url column if not present
if 'track_url' not in df.columns:
    if 'id' in df.columns:
        df['track_url'] = "https://open.spotify.com/track/" + df['id'].astype(str)
    elif 'uri' in df.columns:  # sometimes 'uri' exists: spotify:track:xxxx
        df['track_url'] = df['uri'].apply(lambda x: "https://open.spotify.com/track/" + x.split(':')[-1] if isinstance(x,str) else None)
    else:
        df['track_url'] = None

# Ensure basic columns exist
expected_cols = ['name','artist','track_url','valence','energy','danceability','tempo','loudness','acousticness','speechiness','instrumentalness','liveness']
print("Has expected columns:", {c: (c in df.columns) for c in expected_cols})

# Keep rows with id/name and valence+energy (we need those)
keep_cols = ['id','name','artist','track_url','valence','energy','danceability','tempo','loudness','acousticness','speechiness','instrumentalness','liveness','genre']
# select columns that do exist
present = [c for c in keep_cols if c in df.columns]
df = df[present].copy()

# Convert numeric features to numeric and drop rows with nulls in core features
numeric_features = ['danceability','energy','valence','tempo','loudness','acousticness','speechiness','instrumentalness','liveness']
numeric_present = [c for c in numeric_features if c in df.columns]
for c in numeric_present:
    df[c] = pd.to_numeric(df[c], errors='coerce')

df = df.dropna(subset=['valence','energy'] + numeric_present).reset_index(drop=True)
print("After cleaning rows,cols:", df.shape)
df.head(3)

"""Scale features & save scaler"""

from sklearn.preprocessing import MinMaxScaler
# Select feature set for clustering & similarity (order matters)
feature_cols = numeric_present.copy()  # as found above
print("Using features:", feature_cols)

# Scale with StandardScaler or MinMax (I prefer Standard for distance metrics)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X = scaler.fit_transform(df[feature_cols].values)
joblib.dump(scaler, "/content/scaler.joblib")
print("Saved scaler")

"""KMeans clustering (discover mood clusters)"""

# Choose k (4 is a good start). You can change later (4-8).
k = 7
kmeans = KMeans(n_clusters=k, random_state=42, n_init=20)
labels = kmeans.fit_predict(X)
df['cluster'] = labels
joblib.dump(kmeans, "/content/kmeans.joblib")
print("KMeans done. Cluster sizes:")
print(df['cluster'].value_counts())

# Inspect centroids (in original scaled feature space -> inverse scaling for human readable)
centroids = kmeans.cluster_centers_
# To view centroids in original feature space:
centroids_orig = scaler.inverse_transform(centroids)
centroids_df = pd.DataFrame(centroids_orig, columns=feature_cols)
centroids_df['cluster'] = centroids_df.index
display(centroids_df.round(3))

"""Automatic cluster â†’ mood labeling (heuristic)"""

display(centroids_df[['valence', 'energy']])

# =====================================================
#  FINAL MANUAL 7-EMOTION MAPPING FOR YOUR CLUSTERS
# =====================================================

cluster_to_mood = {
    0: "angry",        # high energy, low valence
    1: "melancholic",  # low valence, mid-low energy
    2: "energetic",    # high energy, mid valence
    3: "happy",        # high energy (party/upbeat)
    4: "calm",         # high valence, smooth energy
    5: "sad",          # lowest valence+energy
    6: "romantic"      # emotional, mid-high energy
}

def centroid_to_mood(row):
    cid = row.name
    return cluster_to_mood.get(cid, "neutral")

mood_to_cluster = {m: c for c, m in cluster_to_mood.items()}
print("Cluster->mood:", cluster_to_mood)
print("Mood->cluster:", mood_to_cluster)

# add mood labels to df
df['mood'] = df['cluster'].map(cluster_to_mood)
df['mood'].value_counts()

"""Recommender functions (returns desired columns)"""

# Feature matrix for similarity (scaled)
feature_matrix = X  # aligned to df rows

# id->index mapping
if 'id' in df.columns:
    id_to_idx = {str(r['id']): i for i, r in df[['id']].iterrows()}
else:
    id_to_idx = {i: i for i in df.index}

# helper to get top N similar rows for a given vector
def top_n_from_vector(vec_scaled, top_n=10):
    sims = cosine_similarity(vec_scaled.reshape(1, -1), feature_matrix)[0]
    top_idx = np.argsort(sims)[::-1][:top_n]
    res = df.iloc[top_idx].copy()
    res = res.assign(similarity=sims[top_idx])

    # Build output DataFrame safely (no SettingWithCopyWarning)
    out_cols = ['track_url', 'artist', 'song_name', 'mood', 'similarity']
    out = pd.DataFrame(columns=out_cols)

    # fill columns safely
    if 'track_url' in res.columns:
        out.loc[:, 'track_url'] = res['track_url'].values
    else:
        out.loc[:, 'track_url'] = None

    if 'artist' in res.columns:
        out.loc[:, 'artist'] = res['artist'].values
    elif 'artists' in res.columns:
        out.loc[:, 'artist'] = res['artists'].values
    else:
        out.loc[:, 'artist'] = None

    if 'name' in res.columns:
        out.loc[:, 'song_name'] = res['name'].values
    elif 'track_name' in res.columns:
        out.loc[:, 'song_name'] = res['track_name'].values
    else:
        out.loc[:, 'song_name'] = None

    out.loc[:, 'mood'] = res['mood'].values
    out.loc[:, 'similarity'] = res['similarity'].values

    return out.reset_index(drop=True)

# Recommend by track id
def recommend_by_track(track_id, top_n=10):
    tid = str(track_id)
    if tid not in id_to_idx:
        raise ValueError("track_id not found")
    idx = id_to_idx[tid]
    vec = feature_matrix[idx]
    return top_n_from_vector(vec, top_n=top_n)

# Recommend by mood (closest to mood centroid)
def recommend_by_mood(mood_label, top_n=15):
    if mood_label not in mood_to_cluster:
        raise ValueError("unknown mood")
    cluster_id = mood_to_cluster[mood_label]
    # compute centroid of cluster in scaled space (mean of feature_matrix rows for that cluster)
    idxs = df.index[df['cluster'] == cluster_id].tolist()
    if len(idxs) == 0:
        return pd.DataFrame(columns=['track_url','artist','song_name','mood','similarity'])
    mood_center = feature_matrix[idxs].mean(axis=0)
    return top_n_from_vector(mood_center, top_n=top_n)

"""Quick interactive tests"""

# show sample rows
display(df[['id','name','artist','track_url','mood']].sample(5))

# Example: recommend by mood
print("Top recommendations for 'energetic':")
try:
    recs = recommend_by_mood('energetic', top_n=10)
    display(recs)
except Exception as e:
    print("Error:", e)

# Example: recommend by seed track (first row)
seed_id = str(df.loc[0,'id'])
print("Seed:", df.loc[0,['name','artist','mood']].to_dict())
print(recommend_by_track(seed_id, top_n=8))

!pip install -q transformers torch
from transformers import pipeline

classifier = pipeline(
    "text-classification",
    model="j-hartmann/emotion-english-distilroberta-base",
    return_all_scores=True
)

def detect_mood_from_text(text):
    text = str(text).lower().strip()

    # Keyword-based detection FIRST
    keyword_map = {
    # Energetic
    "energetic": "energetic",
    "excited": "energetic",
    "hype": "energetic",
    "motivated": "energetic",
    "pumped": "energetic",

    # Calm / Relax
    "relax": "calm",
    "relaxing": "calm",
    "relaxed": "calm",
    "calm": "calm",
    "peaceful": "calm",
    "soothing": "calm",
    "chill": "calm",
    "rest": "calm",
    "tired": "calm",

    # Romantic
    "romantic": "romantic",
    "love": "romantic",
    "affection": "romantic",
    "crush": "romantic",

    # Sad
    "sad": "sad",
    "depressed": "sad",
    "cry": "sad",
    "heartbroken": "sad",
    "lonely": "sad",

    # Angry
    "angry": "angry",
    "mad": "angry",
    "irritated": "angry",
    "annoyed": "angry",

    # Melancholic
    "nostalgic": "melancholic",
    "nostalgia": "melancholic",
    "melancholic": "melancholic",
    "thinking": "melancholic"
}

    # Direct keyword match
    for key, mood in keyword_map.items():
        if key in text:
            return mood

    # Use HuggingFace emotional model
    scores = classifier(text)[0]  # list of dicts
    best = max(scores, key=lambda x: x['score'])
    label = best['label'].lower()

    # Map HF emotions â†’ your clusters
    if label in ["joy", "surprise"]:
        return "happy"
    if label in ["sadness"]:
        return "sad"
    if label in ["anger"]:
        return "angry"
    if label in ["fear", "disgust"]:
        return "melancholic"
    if label in ["neutral"]:
        return "neutral"

    return "neutral"

# ============================================================
# Universal mood mapping (7-cluster or normal version)
# ============================================================

mood_map = {
    "happy": "happy",
    "joy": "neutral",
    "love": "romantic",
    "excited": "energetic",
    "enthusiasm": "energetic",
    "amusement": "happy",
    "grateful": "calm",
    "thankful": "calm",
    "contentment": "calm",
    "relaxed": "calm",
    "calm": "calm",
    "relief": "calm",
    "nostalgia": "melancholic",
    "tender": "romantic",
    "sad": "sad",
    "grief": "sad",
    "loss": "sad",
    "pain": "melancholic",
    "fear": "sad",
    "scared": "sad",
    "disgusted": "sad",
    "angry": "angry",
    "anger": "angry",
    "annoyance": "angry",
    "anxious": "melancholic",
    "nervous": "melancholic",
    "confusion": "neutral",
    "awkwardness": "neutral",
    "bored": "melancholic",
    "craving": "energetic",
    "awe": "energetic",
    "adoration": "romantic",
    "energetic" : "energetic"
}

def normalize_mood_label(label):
    # If detected mood is already a cluster mood:
    if label in mood_to_cluster:
        return label

    # Convert to closest mood category
    return mood_map.get(label, "neutral")

def recommend_songs_from_text_input(user_input, top_n=5):
    detected_mood = detect_mood_from_text(user_input)
    mapped_mood = normalize_mood_label(detected_mood)

    print(f"ğŸ­ Detected mood: {detected_mood} -> using mood: {mapped_mood}\n")

    try:
        recs = recommend_by_mood(mapped_mood, top_n=top_n)

        if recs is not None and not recs.empty:
            print(f"ğŸ¶ Top {top_n} songs for mood '{mapped_mood}':")
            display(recs[['track_url','artist','song_name','mood','similarity']])
        else:
            print("âš ï¸ No songs found for this mood.")
    except Exception as e:
        print("Error:", e)

print(df.columns)
print(df['mood'].unique())
print(df['mood'].value_counts())

recommend_songs_from_text_input("I am feeling depressed ğŸ˜¢", top_n=5)
recommend_songs_from_text_input("I am so energetic and calm ğŸ˜Š", top_n=5)
recommend_songs_from_text_input("Feeling angry", top_n=5)
recommend_songs_from_text_input("Feeling tired", top_n=5)
recommend_songs_from_text_input("I just want to relax ğŸ˜´", top_n=5)

recommend_songs_from_text_input("I am so happy and excited ğŸ˜Š", top_n=5)

"""Save Artifacts"""

df.to_csv("/content/processed_spotify_tracks.csv", index=False)
joblib.dump(feature_cols, "/content/feature_cols.joblib")
joblib.dump(id_to_idx, "/content/id_to_idx.joblib")
joblib.dump(kmeans, "/content/kmeans.joblib")
joblib.dump(scaler, "/content/scaler.joblib")

print("Saved processed CSV and model artifacts")